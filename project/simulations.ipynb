{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Selfish Routing with Positive Externalities\n",
    "\n",
    "## Introduction\n",
    "\n",
    "We consider random networks in which multiple agents with heterogeneous sources and destinations determine their own routes as a best reply to others best replies, the nash equilibrium, that is obtained from an initial state where all agents choose their route on an empty network. \n",
    "\n",
    "There are two primary questions we are interested in learning in the simulations. The firt being, how bad can a graph in terms of the social cost of the Waldrop equilibrium of the full graph versus that of its optimal subgraph. The second is whether or not a greedy algorithm can approximate the results of the exhaustive search, which would indicate that this problem might be submodular in the edges removed. \n",
    "\n",
    "These simulations are computationally expensive, as an exhaustive search is needed to prove the best possible subgraph, however even these crude initial explorations serve as extremely informative regarding these two primary questions in better understanding the nature of this problem. \n",
    "\n",
    "## Setup & Background\n",
    "\n",
    "We define some core concepts related to the questions we are exploring in the simulations:\n",
    "\n",
    "### Wardrop Equilibrium\n",
    "\n",
    "We first define a Wardrop equilibrium, which simply says that given a certain flow $\\textit{f}$, and cost function along a path $c_{\\mathcal{P}}: \\mathcal{P} \\rightarrow \\mathcal{R}^+$, the cost of every equilibrium path is a equal, and less than the cost along any non-equilibrium path:\n",
    "\n",
    "$$\n",
    "c_{\\mathcal{P}}(\\textit{f}) \\leq c_{\\widetilde{\\mathcal{P}}}(\\textit{f} )\n",
    "$$\n",
    "\n",
    "### Social Cost\n",
    "\n",
    "Given multiple sources $S$, multiple agents $A$, a shared destination $t$, and convex and non-decreasing cost function $c(e, f)$, shared up to the paramaterized constant $e$ by each edge (which we can consider to be the distance between two edges in some sort of measure external to the traffic on the network, such as the physical distance of a road), the social cost, $\\Gamma$, for a given graph $G$, at Wardrop equilibrium is given by:\n",
    "\n",
    "$$\n",
    "C(G) = \\sum_{a \\in A} d(S_a, t)\n",
    "$$\n",
    "\n",
    "Where distance function d(s,t) is defined as the distance along the shortest path, $p(s,t)$, between s and t:\n",
    "\n",
    "$$\n",
    "d(s,t) = \\sum_{e \\in p(s,t)} c(e,f)\n",
    "$$\n",
    "\n",
    "### Selfish Ratio\n",
    "\n",
    "Now we can define Selfish Ratio, namely the ratio between the Wardrop equilibrium of the full network, to that of its optimal subnetwork:\n",
    "\n",
    "$$\n",
    "\\beta (G, r, c) = \\max_{H \\subset G} \\frac{C(\\textit{f})}{C(\\textit{f}^H)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Code for Simulation\n",
    "\n",
    "All code can be run via a Jupyter Notebook via the official Jupyter Docker stacks, [scipy-notebook](https://github.com/jupyter/docker-stacks/tree/master/scipy-notebook). The code can be found in the /lib folder of the same repository as this notebook. Note that it is parallelized and best run on a machine with many cores, the current simulations take ~2 hours on a machine with 32 cores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": "worksheet-0",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "!conda uninstall --yes networkx\n",
    "!pip install --upgrade git+git://github.com/networkx/networkx.git#egg=networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Our code \n",
    "from lib.equilibrium import *\n",
    "from lib.generation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def random_distances(graph, bottom = 0.5, top = 2, mult = 1):\n",
    "    n = graph.shape[0]\n",
    "    rands = (np.random.uniform(bottom,top,n**2).reshape((n,n))*mult)\n",
    "    return graph * rands\n",
    "\n",
    "def base_setup(edges, n, A, cost_fn):\n",
    "    agents = random_placements(n, A)\n",
    "    graph = random_distances(path_to_mat(edges, n))\n",
    "    edges = list(nx.DiGraph(graph).edges(data=True))\n",
    "    state = initial_state(agents, graph)\n",
    "    new_state = find_equilibrium(state, graph, cost_fn)\n",
    "    graphs = [path_to_mat(c, n) for c in combinations(edges)]\n",
    "    return new_state, graph, graphs, cost_fn\n",
    "\n",
    "def barabasi(n, attch):\n",
    "    edges = nx.barabasi_albert_graph(n, attch).edges()\n",
    "    return list(edges) + map(lambda t: (t[1],t[0]), edges)\n",
    "\n",
    "def erdos(n, p):\n",
    "    return list(nx.erdos_renyi_graph(n, p, directed = True).edges())\n",
    "\n",
    "def full(n):\n",
    "    adj = np.ones((n,n))\n",
    "    return list(nx.DiGraph(adj).edges())\n",
    "\n",
    "def run_one(state, full_graph, graphs, cost_fn, iters = 100):\n",
    "    return [\n",
    "        score_graph(state, full_graph, cost_fn), \n",
    "        find_optimum_subgraph(state, full_graph, cost_fn, iters)[0],\n",
    "        combinatorial_optimum(state, graphs, cost_fn)[0],\n",
    "        float((full_graph != 0).sum())/(full_graph.shape[0]**2) # sparsity\n",
    "    ]\n",
    "\n",
    "def run(m, n, A, cost_fn, setup, args):\n",
    "    def run_model():\n",
    "        try: \n",
    "            return run_one(*base_setup(setup(n, *args), n, A, cost_fn))\n",
    "        except nx.exception.NetworkXNoPath:\n",
    "            return None\n",
    "        \n",
    "    res = [run_model() for _ in range(m)]\n",
    "    res = [r for r in res if r is not None]\n",
    "    df = pd.DataFrame(np.array(res), \n",
    "                      columns = [\"original\", \"greedy\", \"exhaustive\", \"sparsity\"])\n",
    "    return df.assign(generator = setup.__name__, \n",
    "                     generator_param = args[0],\n",
    "                     cost = cost_fn.__name__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Functions\n",
    "\n",
    "We examine two cost functions, one linear, one exponential, both convex and decreasing in their parametarized flow. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def linear_cost(f,c):\n",
    "    return c * 1/f if f > 0 else float('inf')\n",
    "\n",
    "def exp_cost(f,c):\n",
    "    return c * (.5)**(f - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": "worksheet-0",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([\n",
    "    run(5, 6, 8, linear_cost, erdos, args = [.8]),\n",
    "    run(5, 6, 8, exp_cost, erdos, args = [.8]),\n",
    "    run(5, 6, 8, linear_cost, barabasi, args = [3]),\n",
    "    run(5, 6, 8, exp_cost, barabasi, args = [3]),\n",
    "    run(5, 6, 8, linear_cost, erdos, args = [.5]),\n",
    "    run(5, 6, 8, exp_cost, erdos, args = [.5]),\n",
    "    run(5, 6, 8, linear_cost, barabasi, args = [2]),\n",
    "    run(5, 6, 8, exp_cost, barabasi, args = [2])\n",
    "    ], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Selfish Ratio\n",
    "\n",
    "These initial simulations don't allow us to bound the Selfish Ratio, but they do show that there is very often some inefficiency in the network, but that inefficiency is rarely very large. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "ratio = df.original/df.exhaustive\n",
    "p = sns.kdeplot(ratio, bw = .2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## $\\epsilon$-Approximation Error of Greedy Algorithm\n",
    "\n",
    "From the results of this initial simulation, it is clear that we can't necessarily bound the lower end of the Greedy algorithm, it is not clear that it cannot be arbitrarily bad given a particular network structure. We can, however, see clearly that in these particular networks tested, it finds a perfect solution a large percentage of the time, which is also very interesting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "epsilon = (df.exhaustive - df.greedy)/df.exhaustive\n",
    "p = sns.kdeplot(epsilon, bw = .01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "np.min(epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selfish Ratio as a Function of Sparsity\n",
    "\n",
    "We will need more simulations to conclude anything with regards to this relationship. Theory points us to the selfish ratio being worse the more full the graph is, however we do not see evidence of that in these limited simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "ein.tags": "worksheet-0",
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "df = df.assign(selfish_ratio = df.original/df.exhaustive)\n",
    "df.plot(y = \"selfish_ratio\", x = \"sparsity\", kind = \"scatter\", c = \"cost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": "simulations.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
